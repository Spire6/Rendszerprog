{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data acquisition\n",
    "- Large amount of data are available on the net\n",
    "- Data processing can be automated\n",
    "    1. exploring the data source\n",
    "    2. analyzing raw data gathered from the source to find information\n",
    "        - find information\n",
    "        - define rules to extract\n",
    "    3. extract and process information from data with a repeated, autmated flow\n",
    "        1. extract information based on rules defined by analysis\n",
    "        2. store information\n",
    "        3. process information\n",
    "    4. Scedule execution\n",
    "        1. wait for the next loop to start\n",
    "        2. start the next loop\n",
    "\n",
    "## Web scrapping\n",
    "- When data is extracted from public web sources\n",
    "- Exploring data source\n",
    "    1. creating requests to data source\n",
    "    2. examine response HTML/JSON contents\n",
    "        - find information in structured response\n",
    "        - define regular expressions/search flows to find information\n",
    "    3. extract and process information\n",
    "        1. make request\n",
    "        2. follow rules to extract information\n",
    "        3. convert extracted information to requisted format\n",
    "        4. augment extracted informtion with additional (administrtarional) information\n",
    "        4. store information \n",
    "        5. process information\n",
    "        6. generate output reports\n",
    "    4. schedule process python or OS functionality\n",
    "        1. create scheduler\n",
    "        2. setup scheduler\n",
    "        3. run scheduler\n",
    "    \n",
    "Before doing WebScrapping:\n",
    "- always check copyright information\n",
    "- be aware of hacker attak identification processes and their consequences  \n",
    "    frequent requests could:\n",
    "        - cause host to crash\n",
    "        - could be identified as DoS attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source: [Foreign currency exchange rates of Magyar Nemzeti Bank (Central Bank of Hungary)](https://www.mnb.hu/arfolyamok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data source analysis\n",
    "To analyse structure of data source use:\n",
    "- integrated developer tools of a browser\n",
    "- HTTP request debugger tools (like PostMan)\n",
    "\n",
    "\n",
    "Main tasks of analysis:\n",
    "- to examine structure of HTTP response, find and identify required information\n",
    "- identify the enclosing structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requesting information from web\n",
    "Using HTTP protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "URL = 'https://www.mnb.hu/arfolyamok'\n",
    "page = requests.get(URL)\n",
    "print(page.content[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML decoding\n",
    "For extracting information from a static HTML response, decoding of HTML formatted data is mecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install BeautifulSoup4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining rules and flow to extract information\n",
    "When static HTML page is decoded to python data structures, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soup.find(id='fd-arg-IsBlind')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tables = soup.find_all('table', class_='datatable')\n",
    "print(len(data_tables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding HTML table rows containing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows = []\n",
    "for table in data_tables:\n",
    "    table_body = table.find('tbody')\n",
    "    rows = table_body.find_all('tr')\n",
    "    all_rows.extend(rows)\n",
    "    print(len(rows))\n",
    "print(\"sum: \", len(all_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting and augmenting acquired information ```items``` array\n",
    "Finding HTML cells of data, extracting and converting data to the required format.  \n",
    "Gathered data is augmented with timestamp to process data changes in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date_and_time = datetime.now()\n",
    "time_string = current_date_and_time.strftime(\"%Y/%m/%d %H:%M\")\n",
    "acquired_data = {\"timestamp\": time_string}\n",
    "\n",
    "items = []\n",
    "converters = [\n",
    "    {\"property_name\": \"code\", \"method\": None},\n",
    "    {\"property_name\": \"name\", \"method\": None},\n",
    "    {\"property_name\": \"unit\", \"method\": int},\n",
    "    {\"property_name\": \"value\", \"method\": float}\n",
    "]\n",
    "for row in all_rows:\n",
    "    cells = row.find_all('td')\n",
    "    items.append({})\n",
    "    for i in range(0, len(cells)):\n",
    "        data = cells[i].text.strip().replace(',', '.')\n",
    "        items[-1][converters[i][\"property_name\"]] = \\\n",
    "            data if converters[i][\"method\"] is None else converters[i][\"method\"](data)\n",
    "\n",
    "acquired_data[\"items\"] = items\n",
    "print(acquired_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedule the process using Python scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before scheduling a task, a function have to be created to let is start scheduled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install schedule\n",
    "import schedule\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data acquisition is sceruded to run every 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule.every(15).minutes.do(my_data_acquisition_method) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "## Get currency exchange rates from \n",
    "[XE Currency Charts](https://www.xe.com/currencycharts/)\n",
    "## Modify first acquisition script to get currency/HUF exchange rates\n",
    "## Combine both data sources to a single storage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
